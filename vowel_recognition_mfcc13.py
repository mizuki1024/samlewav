"""
MFCC13æ¬¡å…ƒã‚’ä½¿ç”¨ã—ãŸæ¯éŸ³èªè­˜ã‚·ã‚¹ãƒ†ãƒ 
å…¨13æ¬¡å…ƒã®MFCCç‰¹å¾´é‡ã‚’æ´»ç”¨ã—ã¦é«˜ç²¾åº¦ãªæ¯éŸ³èªè­˜ã‚’å®Ÿç¾
"""

# === ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ===
import os
import numpy as np
import sounddevice as sd
import soundfile as sf
import librosa
import matplotlib.pyplot as plt
from time import sleep

# === ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆMacå¯¾å¿œï¼‰ ===
plt.rcParams['font.family'] = 'AppleGothic'  # Macç”¨ãƒ•ã‚©ãƒ³ãƒˆ

# === éŸ³å£°å‡¦ç†è¨­å®š ===
RATE = 16000  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆ16kHzï¼‰
DURATION = 1.0  # éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
N_MFCC = 13  # MFCCã®æ¬¡å…ƒæ•°ï¼ˆå…¨13æ¬¡å…ƒä½¿ç”¨ï¼‰
RECORDINGS_DIR = "recordings_formant"  # éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜å…ˆ
VOWELS = ['a', 'i', 'u', 'e', 'o']  # å¯¾è±¡ã¨ã™ã‚‹æ¯éŸ³
SAMPLES_PER_VOWEL = 3  # æ¯éŸ³ã”ã¨ã®ã‚µãƒ³ãƒ—ãƒ«æ•°

# === æ¯éŸ³ã®è‰²ãƒãƒƒãƒ”ãƒ³ã‚° ===
COLOR_MAP = {
    'a': 'red',
    'i': 'blue',
    'u': 'green',
    'e': 'purple',
    'o': 'orange'
}

# === æ¯éŸ³ã”ã¨ã®ç™ºéŸ³ã‚¢ãƒ‰ãƒã‚¤ã‚¹ ===
ADVICE_MAP = {
    'a': "å£ã‚’å¤§ããç¸¦ã«é–‹ã‘ã€èˆŒã¯ä¸‹ã«è½ã¨ã—ã¾ã—ã‚‡ã†ã€‚",
    'i': "å£ã‚’æ¨ªã«å¼•ã„ã¦ã€èˆŒã¯å‰ã«å‡ºã™ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚",
    'u': "å”‡ã‚’ã™ã¼ã‚ã¦ã€èˆŒã‚’å¾Œã‚ã«å¼•ãã¾ã—ã‚‡ã†ã€‚",
    'e': "å£è§’ã‚’å°‘ã—ä¸Šã’ã€èˆŒã‚’ã‚„ã‚„å‰ã«å‡ºã—ã¾ã—ã‚‡ã†ã€‚",
    'o': "å”‡ã‚’ä¸¸ãçªãå‡ºã—ã€èˆŒã‚’å¾Œã‚ã«å¼•ãã¾ã—ã‚‡ã†ã€‚"
}

# === éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰MFCCç‰¹å¾´é‡ã‚’æŠ½å‡º ===
def extract_features():
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰13æ¬¡å…ƒMFCCã‚’æŠ½å‡º"""
    X_mfcc, y = [], []
    
    for vowel in VOWELS:
        for i in range(1, SAMPLES_PER_VOWEL + 1):
            filepath = os.path.join(RECORDINGS_DIR, f"{vowel}_{i}.wav")
            if os.path.exists(filepath):
                # éŸ³å£°èª­ã¿è¾¼ã¿
                y_data, sr = librosa.load(filepath, sr=RATE)
                
                # ç„¡éŸ³åŒºé–“é™¤å»
                y_data, _ = librosa.effects.trim(y_data, top_db=20)
                
                # MFCCæŠ½å‡ºï¼ˆ13æ¬¡å…ƒã™ã¹ã¦ï¼‰
                mfcc = librosa.feature.mfcc(y=y_data, sr=sr, n_mfcc=N_MFCC)
                X_mfcc.append(np.mean(mfcc, axis=1))  # æ™‚é–“æ–¹å‘ã®å¹³å‡
                y.append(vowel)
            else:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
    
    return np.array(X_mfcc), np.array(y)

# === æ¯éŸ³ã”ã¨ã«MFCCã®å¹³å‡ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ ===
def build_templates(X_mfcc, y):
    """å„æ¯éŸ³ã®MFCCãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ"""
    templates = {}
    
    for vowel in VOWELS:
        indices = y == vowel
        if np.any(indices):
            templates[vowel] = np.mean(X_mfcc[indices], axis=0)
    
    return templates

# === ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºéŸ³ã‚’éŒ²éŸ³ ===
def record_audio(path):
    """ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’éŒ²éŸ³"""
    print("ğŸ¤ ç™ºéŸ³ã—ã¦ãã ã•ã„...")
    audio = sd.rec(int(RATE * DURATION), samplerate=RATE, channels=1)
    sd.wait()
    sf.write(path, audio, RATE)

# === éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ã‹ã‚‰ç‰¹å¾´ã‚’æŠ½å‡º ===
def extract_user_features(filepath):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ã‹ã‚‰13æ¬¡å…ƒMFCCã‚’æŠ½å‡º"""
    # éŸ³å£°èª­ã¿è¾¼ã¿
    y_data, sr = librosa.load(filepath, sr=RATE)
    
    # ç„¡éŸ³åŒºé–“é™¤å»
    y_data, _ = librosa.effects.trim(y_data, top_db=20)
    
    # MFCCæŠ½å‡ºï¼ˆ13æ¬¡å…ƒã™ã¹ã¦ï¼‰
    mfcc = librosa.feature.mfcc(y=y_data, sr=sr, n_mfcc=N_MFCC)
    mfcc_features = np.mean(mfcc, axis=1)
    
    return mfcc_features

# === ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®MFCCã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨æ¯”è¼ƒã—ã¦åˆ†é¡ ===
def classify(user_mfcc, templates):
    """13æ¬¡å…ƒMFCCã«ã‚ˆã‚‹æ¯éŸ³åˆ†é¡"""
    # å„æ¯éŸ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’è¨ˆç®—
    distances = {}
    for vowel, template_mfcc in templates.items():
        # 13æ¬¡å…ƒå…¨ä½“ã§ã®è·é›¢ã‚’è¨ˆç®—
        distance = np.linalg.norm(user_mfcc - template_mfcc)
        distances[vowel] = distance
    
    # è·é›¢ãŒè¿‘ã„é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_distances = sorted(distances.items(), key=lambda x: x[1])
    
    return sorted_distances, distances

# === ç™ºéŸ³ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹è¡¨ç¤º ===
def show_advice(vowel, score):
    """ç™ºéŸ³ã«å¯¾ã™ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º"""
    print("\nğŸ§ª ç™ºéŸ³è©•ä¾¡:")
    if score < 5:
        print("âœ… éå¸¸ã«è‰¯ã„ç™ºéŸ³ã§ã™ï¼")
    elif score < 10:
        print("â­ è‰¯ã„ç™ºéŸ³ã§ã™ï¼")
    elif score < 15:
        print("âš ï¸ ã‚‚ã†å°‘ã—ç·´ç¿’ã—ã¾ã—ã‚‡ã†ã€‚")
    else:
        print("âŒ ç™ºéŸ³ã‚’æ”¹å–„ã—ã¾ã—ã‚‡ã†ã€‚ä»¥ä¸‹ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚")
        print(f"ğŸ—£ ã€Œ{vowel}ã€ã®ç™ºéŸ³ã‚¢ãƒ‰ãƒã‚¤ã‚¹: {ADVICE_MAP.get(vowel, 'ç·´ç¿’ã‚’ç¶šã‘ã¾ã—ã‚‡ã†ã€‚')}")

# === MFCCä¿‚æ•°ã®é‡è¦åº¦ã‚’åˆ†æãƒ»è¡¨ç¤º ===
def analyze_mfcc_importance(X_mfcc, y, templates):
    """13æ¬¡å…ƒMFCCã®å„ä¿‚æ•°ã®é‡è¦åº¦ã‚’åˆ†æ"""
    print("\nğŸ“Š 13æ¬¡å…ƒMFCCã«ã‚ˆã‚‹æ¯éŸ³è­˜åˆ¥åˆ†æ:")
    print(f"  ä½¿ç”¨ã—ã¦ã„ã‚‹MFCCä¿‚æ•°: MFCC0ã€œMFCC12 (å…¨13æ¬¡å…ƒ)")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {X_mfcc.shape[0]}")
    
    # æ¯éŸ³ã”ã¨ã®ç‰¹å¾´ã‚’è¨ˆç®—
    mfcc_by_vowel = {}
    for vowel in VOWELS:
        indices = y == vowel
        if np.any(indices):
            vowel_data = X_mfcc[indices]
            mfcc_by_vowel[vowel] = {
                'mean': np.mean(vowel_data, axis=0),
                'std': np.std(vowel_data, axis=0)
            }
    
    # å„MFCCä¿‚æ•°ã®æ¯éŸ³é–“åˆ†æ•£ã‚’è¨ˆç®—ï¼ˆè­˜åˆ¥åŠ›ã®æŒ‡æ¨™ï¼‰
    mfcc_variances = []
    for i in range(N_MFCC):
        values = [mfcc_by_vowel[v]['mean'][i] for v in VOWELS if v in mfcc_by_vowel]
        if values:
            mfcc_variances.append(np.var(values))
        else:
            mfcc_variances.append(0)
    
    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
    importance_ranking = np.argsort(mfcc_variances)[::-1]
    
    print("\nğŸ“Š æ¯éŸ³è­˜åˆ¥ã«é‡è¦ãªMFCCä¿‚æ•°ï¼ˆåˆ†æ•£ãŒå¤§ãã„é †ï¼‰:")
    for rank, idx in enumerate(importance_ranking[:5]):
        print(f"  {rank+1}. MFCC{idx}: åˆ†æ•£={mfcc_variances[idx]:.3f}")
    
    # å¯è¦–åŒ–
    create_mfcc_analysis_plots(mfcc_by_vowel, mfcc_variances, X_mfcc, y)

# === MFCCåˆ†æçµæœã®å¯è¦–åŒ– ===
def create_mfcc_analysis_plots(mfcc_by_vowel, mfcc_variances, X_mfcc, y):
    """13æ¬¡å…ƒMFCCã®åˆ†æçµæœã‚’å¯è¦–åŒ–"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1. å„æ¯éŸ³ã®MFCCãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    ax1 = axes[0, 0]
    for vowel in VOWELS:
        if vowel in mfcc_by_vowel:
            color = COLOR_MAP.get(vowel, 'gray')
            mean_vals = mfcc_by_vowel[vowel]['mean']
            ax1.plot(range(N_MFCC), mean_vals, 
                    marker='o', label=vowel, color=color, linewidth=2)
    
    ax1.set_xlabel('MFCCä¿‚æ•°')
    ax1.set_ylabel('å¹³å‡å€¤')
    ax1.set_title('å„æ¯éŸ³ã®13æ¬¡å…ƒMFCCãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«')
    ax1.set_xticks(range(N_MFCC))
    ax1.set_xticklabels([f'{i}' for i in range(N_MFCC)])
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    
    # 2. MFCCä¿‚æ•°ã®é‡è¦åº¦ï¼ˆæ¯éŸ³é–“åˆ†æ•£ï¼‰
    ax2 = axes[0, 1]
    bars = ax2.bar(range(N_MFCC), mfcc_variances)
    ax2.set_xlabel('MFCCä¿‚æ•°')
    ax2.set_ylabel('æ¯éŸ³é–“åˆ†æ•£')
    ax2.set_title('å„MFCCä¿‚æ•°ã®æ¯éŸ³è­˜åˆ¥åŠ›')
    ax2.set_xticks(range(N_MFCC))
    ax2.set_xticklabels([f'{i}' for i in range(N_MFCC)])
    ax2.grid(True, alpha=0.3, axis='y')
    
    # é‡è¦åº¦ã®é«˜ã„ä¿‚æ•°ã‚’è‰²åˆ†ã‘
    max_var = np.max(mfcc_variances)
    for i, bar in enumerate(bars):
        if mfcc_variances[i] > max_var * 0.7:
            bar.set_color('darkred')
        elif mfcc_variances[i] > max_var * 0.4:
            bar.set_color('orange')
        else:
            bar.set_color('lightcoral')
    
    # 3. æ¯éŸ³ã”ã¨ã®MFCCãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    ax3 = axes[1, 0]
    vowel_list = [v for v in VOWELS if v in mfcc_by_vowel]
    mfcc_matrix = np.array([mfcc_by_vowel[v]['mean'] for v in vowel_list])
    
    im = ax3.imshow(mfcc_matrix.T, cmap='RdBu_r', aspect='auto')
    ax3.set_xlabel('æ¯éŸ³')
    ax3.set_ylabel('MFCCä¿‚æ•°')
    ax3.set_title('æ¯éŸ³åˆ¥MFCCä¿‚æ•°ã®å€¤ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰')
    ax3.set_xticks(range(len(vowel_list)))
    ax3.set_xticklabels(vowel_list)
    ax3.set_yticks(range(N_MFCC))
    ax3.set_yticklabels([f'MFCC{i}' for i in range(N_MFCC)])
    
    # ã‚«ãƒ©ãƒ¼ãƒãƒ¼
    cbar = plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)
    cbar.set_label('MFCCå€¤')
    
    # 4. ç‰¹å®šã®MFCCä¿‚æ•°ã§ã®æ¯éŸ³åˆ†å¸ƒ
    ax4 = axes[1, 1]
    # æœ€ã‚‚è­˜åˆ¥åŠ›ã®é«˜ã„2ã¤ã®MFCCä¿‚æ•°ã‚’é¸æŠ
    top_indices = np.argsort(mfcc_variances)[::-1][:2]
    mfcc1_idx, mfcc2_idx = top_indices[0], top_indices[1]
    
    for vowel in VOWELS:
        indices = y == vowel
        if np.any(indices):
            vowel_data = X_mfcc[indices]
            color = COLOR_MAP.get(vowel, 'gray')
            ax4.scatter(vowel_data[:, mfcc1_idx], vowel_data[:, mfcc2_idx],
                       color=color, label=vowel, alpha=0.7, s=100)
    
    ax4.set_xlabel(f'MFCC{mfcc1_idx} å€¤')
    ax4.set_ylabel(f'MFCC{mfcc2_idx} å€¤')
    ax4.set_title(f'æœ€ã‚‚è­˜åˆ¥åŠ›ã®é«˜ã„MFCCä¿‚æ•°ã§ã®æ¯éŸ³åˆ†å¸ƒ')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('mfcc13_analysis.png', dpi=150)
    print("ğŸ“Š 13æ¬¡å…ƒMFCCåˆ†æçµæœã‚’ 'mfcc13_analysis.png' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    plt.show()

# === ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ç”¨ã®ãƒ—ãƒ­ãƒƒãƒˆåˆæœŸåŒ– ===
def init_realtime_plot(templates):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨ã®ãƒ—ãƒ­ãƒƒãƒˆã‚’åˆæœŸåŒ–"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
    
    # å·¦å´ï¼šMFCCãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º
    ax1.set_xlabel('MFCCä¿‚æ•°')
    ax1.set_ylabel('å€¤')
    ax1.set_title('MFCCãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰')
    ax1.set_xlim(-0.5, N_MFCC-0.5)
    ax1.set_ylim(-30, 30)
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    for vowel, template in templates.items():
        color = COLOR_MAP.get(vowel, 'gray')
        ax1.plot(range(N_MFCC), template, 
                color=color, alpha=0.3, linewidth=1, linestyle='--')
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®MFCCç”¨ã®ãƒ©ã‚¤ãƒ³ï¼ˆåˆæœŸåŒ–ï¼‰
    user_line, = ax1.plot([], [], 'r-', linewidth=2, marker='o', markersize=6)
    
    # å³å´ï¼šè·é›¢ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
    ax2.set_xlabel('æ¯éŸ³')
    ax2.set_ylabel('è·é›¢')
    ax2.set_title('å„æ¯éŸ³ã¨ã®è·é›¢')
    ax2.set_ylim(0, 30)
    ax2.grid(True, alpha=0.3, axis='y')
    
    # åˆæœŸãƒãƒ¼
    bars = ax2.bar(VOWELS, [0]*len(VOWELS), 
                   color=[COLOR_MAP[v] for v in VOWELS])
    
    plt.tight_layout()
    return fig, ax1, ax2, user_line, bars

# === ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ãƒƒãƒˆã®æ›´æ–° ===
def update_realtime_plot(user_mfcc, distances, predicted, user_line, bars, ax1, ax2):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ãƒƒãƒˆã‚’æ›´æ–°"""
    # MFCCãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    user_line.set_data(range(N_MFCC), user_mfcc)
    
    # è·é›¢ãƒãƒ¼ã‚’æ›´æ–°
    dist_values = [distances[v] for v in VOWELS]
    for bar, dist in zip(bars, dist_values):
        bar.set_height(dist)
    
    # äºˆæ¸¬çµæœã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    for i, vowel in enumerate(VOWELS):
        if vowel == predicted:
            bars[i].set_edgecolor('red')
            bars[i].set_linewidth(3)
        else:
            bars[i].set_edgecolor('black')
            bars[i].set_linewidth(1)
    
    # ã‚¿ã‚¤ãƒˆãƒ«æ›´æ–°
    ax1.set_title(f'MFCCãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« - æ¨å®š: ã€Œ{predicted}ã€')
    
    plt.pause(0.01)

# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
def main():
    print("ğŸµ 13æ¬¡å…ƒMFCCã‚’ä½¿ç”¨ã—ãŸæ¯éŸ³èªè­˜ã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸ“¦ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ä¸­...")
    
    # ç‰¹å¾´æŠ½å‡º
    X_mfcc, y = extract_features()
    
    if len(X_mfcc) == 0:
        print("âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚recordings_formant ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
    templates = build_templates(X_mfcc, y)
    
    # åˆå›ã®ã¿MFCCåˆ†æã‚’è¡¨ç¤ºï¼ˆãã®å¾Œã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    if not hasattr(main, 'analyzed'):
        analyze_mfcc_importance(X_mfcc, y, templates)
        main.analyzed = True
        input("\nğŸ“Š åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜ã‚’é–‹å§‹...")
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ãƒƒãƒˆåˆæœŸåŒ–
    fig, ax1, ax2, user_line, bars = init_realtime_plot(templates)
    plt.ion()  # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ON
    
    print("\nğŸŸ¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¯éŸ³èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆCtrl+Cã§åœæ­¢ï¼‰")
    print("ğŸ“Š 13æ¬¡å…ƒã™ã¹ã¦ã®MFCCä¿‚æ•°ã‚’ä½¿ç”¨ã—ã¦é«˜ç²¾åº¦ãªèªè­˜ã‚’è¡Œã„ã¾ã™")
    
    try:
        while True:
            audio_path = "user_input.wav"
            record_audio(audio_path)  # éŒ²éŸ³
            
            # ç‰¹å¾´æŠ½å‡ºï¼ˆ13æ¬¡å…ƒMFCCï¼‰
            user_mfcc = extract_user_features(audio_path)
            
            # åˆ†é¡
            results, distances = classify(user_mfcc, templates)
            predicted, dist = results[0]  # æœ€ã‚‚è¿‘ã„æ¯éŸ³ã¨è·é›¢
            
            # çµæœè¡¨ç¤º
            print("\n=== åˆ¤å®šçµæœ ===")
            print(f"ğŸ—£ æ¨å®š: ã€Œ{predicted}ã€ / è·é›¢ã‚¹ã‚³ã‚¢: {dist:.2f}")
            
            # MFCCã®è©³ç´°æƒ…å ±
            print(f"ğŸ“Š 13æ¬¡å…ƒMFCCä½¿ç”¨")
            print("ğŸ“Š é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
            for i, (v, d) in enumerate(results):
                print(f"  {i+1}. {v}ï¼ˆè·é›¢: {d:.2f}ï¼‰")
            
            # ã‚¢ãƒ‰ãƒã‚¤ã‚¹è¡¨ç¤º
            show_advice(predicted, dist)
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ãƒƒãƒˆæ›´æ–°
            update_realtime_plot(user_mfcc, distances, predicted, 
                               user_line, bars, ax1, ax2)
            
            sleep(0.2)
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ çµ‚äº†ã—ã¾ã—ãŸã€‚")
        plt.ioff()  # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰OFF
        plt.close('all')

# === ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ ===
if __name__ == "__main__":
    # recordingsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(RECORDINGS_DIR):
        print(f"ğŸ“ {RECORDINGS_DIR}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™...")
        os.makedirs(RECORDINGS_DIR)
        print(f"âš ï¸ {RECORDINGS_DIR}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ¯éŸ³ã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
        print("ğŸ’¡ test3-1.py ã‚’å®Ÿè¡Œã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã‚’éŒ²éŸ³ã§ãã¾ã™")
    else:
        main()